{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a short description of the dataset. You may also plot histograms to see the distribution of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris dataset is a famous dataset in machine learning. It consists of 150 iris flowers split evenly into three categories. There are four features: Sepal Length, Sepal Width, Petal Length, Petal Width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_len  sepal_wid  petal_len  petal_wid           class\n",
       "145        6.7        3.0        5.2        2.3  Iris-virginica\n",
       "146        6.3        2.5        5.0        1.9  Iris-virginica\n",
       "147        6.5        3.0        5.2        2.0  Iris-virginica\n",
       "148        6.2        3.4        5.4        2.3  Iris-virginica\n",
       "149        5.9        3.0        5.1        1.8  Iris-virginica"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "    header=None, \n",
    "    sep=',')\n",
    "\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data table into data X and class labels y\n",
    "X = df.iloc[:,0:4].values\n",
    "y = df.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = {1:'Iris-Setosa', 2: 'Iris-Versicolor', 3: 'Iris-Virginica'}\n",
    "#features = {0: 'Sepal Length', 1: 'Sepal Width', 2: 'Petal Length', 3: 'Petal Width'}\n",
    "#plt.figure(figsize=(10,8))\n",
    "#for cnt in range(4):\n",
    "#    plt.subplot(2,2,cnt+1)\n",
    "#    for lab in labels:\n",
    "#        plt.hist(X[y==lab, cnt], label = lab, bins = 10, alpha = 0.3)\n",
    "#    plt.xlabel(features[cnt])\n",
    "#plt.tight_layout()\n",
    "#plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the dataset. You may use scikit learn for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code...\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigendecomposition - Computing Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix \n",
      "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
      " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
      " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
      " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy covariance matrix: \n",
      "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
      " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
      " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
      " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Eigen Vectors and Eigen Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors:\n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "Eigenvalues:\n",
      "[2.93035378 0.92740362 0.14834223 0.02074601]\n"
     ]
    }
   ],
   "source": [
    "# Your code...\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print(\"Eigenvectors:\")\n",
    "print(eig_vecs)\n",
    "print(\"Eigenvalues:\")\n",
    "print(eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix\n",
    "\n",
    "Especially, in the field of \"Finance,\" the correlation matrix typically used instead of the covariance matrix. However, the eigendecomposition of the covariance matrix (if the input data was standardized) yields the same results as a eigendecomposition on the correlation matrix, since the correlation matrix can be understood as the normalized covariance matrix. Eigendecomposition of the standardized data based on the correlation matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Eigen Vectors and Eigen Values for the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors:\n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "Eigenvalues:\n",
      "[2.91081808 0.92122093 0.14735328 0.02060771]\n"
     ]
    }
   ],
   "source": [
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "\n",
    "# Your code...\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "\n",
    "print(\"Eigenvectors:\")\n",
    "print(eig_vecs)\n",
    "print(\"Eigenvalues:\")\n",
    "print(eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors:\n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "Eigenvalues:\n",
      "[2.91081808 0.92122093 0.14735328 0.02060771]\n"
     ]
    }
   ],
   "source": [
    "cor_mat2 = np.corrcoef(X.T)\n",
    "\n",
    "# Your code...\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "\n",
    "print(\"Eigenvectors:\")\n",
    "print(eig_vecs)\n",
    "print(\"Eigenvalues:\")\n",
    "print(eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Vector Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52237162, -0.37231836,  0.72101681,  0.26199559],\n",
       "       [ 0.26335492, -0.92555649, -0.24203288, -0.12413481],\n",
       "       [-0.58125401, -0.02109478, -0.14089226, -0.80115427],\n",
       "       [-0.56561105, -0.06541577, -0.6338014 ,  0.52354627]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u,s,v = np.linalg.svd(X_std.T)\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical goal of a PCA is to reduce the dimensionality of the original feature space by projecting it onto a smaller subspace, where the eigenvectors will form the axes. However, the eigenvectors only define the directions of the new axis, since they have all the same unit length 1, which can confirmed by the following two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything ok!\n"
     ]
    }
   ],
   "source": [
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "print('Everything ok!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decide which eigenvector(s) can be dropped without losing too much information for the construction of lower-dimensional subspace, we need to inspect the corresponding eigenvalues: The eigenvectors with the lowest eigenvalues bear the least information about the distribution of the data; those are the ones can be dropped.\n",
    "In order to do so, the common approach is to rank the eigenvalues from highest to lowest in order choose the top 𝑘 eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write code for the following..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "2.9108180837520523\n",
      "0.9212209307072246\n",
      "0.14735327830509562\n",
      "0.02060770723562493\n"
     ]
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "# Your Code\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "# Your Code\n",
    "eig_pairs.sort(key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are reducing the 4-dimensional feature space to a 2-dimensional feature subspace, by choosing the \"top 2\" eigenvectors with the highest eigenvalues to construct our 𝑑×𝑘-dimensional eigenvector matrix 𝐖."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[ 0.52237162 -0.37231836]\n",
      " [-0.26335492 -0.92555649]\n",
      " [ 0.58125401 -0.02109478]\n",
      " [ 0.56561105 -0.06541577]]\n"
     ]
    }
   ],
   "source": [
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1), \n",
    "                      eig_pairs[1][1].reshape(4,1)))\n",
    "\n",
    "print('Matrix W:\\n', matrix_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'red'>TODO</font>: Try to plot projection onto the new feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for LDA :-\n",
    "\n",
    "- Compute d-dimensional mean vectors for different classes from the dataset, where d is the dimension of feature space.\n",
    "- Compute in-between class and with-in class scatter matrices.\n",
    "- Compute eigen vectors and corresponding eigen values for the scatter matrices.\n",
    "- Choose k eigen vectors corresponding to top k eigen values to form a transformation matrix of dimension d x k.\n",
    "- Transform the d-dimensional feature space X to k-dimensional feature space X_lda via the transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(4),\n",
    "                  ('sepal length in cm',\n",
    "                  'sepal width in cm',\n",
    "                  'petal length in cm',\n",
    "                  'petal width in cm', ))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "145                 6.7                3.0                 5.2   \n",
       "146                 6.3                2.5                 5.0   \n",
       "147                 6.5                3.0                 5.2   \n",
       "148                 6.2                3.4                 5.4   \n",
       "149                 5.9                3.0                 5.1   \n",
       "\n",
       "     petal width in cm     class label  \n",
       "145                2.3  Iris-virginica  \n",
       "146                1.9  Iris-virginica  \n",
       "147                2.0  Iris-virginica  \n",
       "148                2.3  Iris-virginica  \n",
       "149                1.8  Iris-virginica  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.io.parsers.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "    header=None,\n",
    "    sep=',',\n",
    "    )\n",
    "df.columns = [l for i,l in sorted(feature_dict.items())] + ['class label']\n",
    "df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is more convenient to work with numerical values, we will use the LabelEncode from the scikit-learn library to convert the class labels into numbers: 1, 2, and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[:].values\n",
    "X = X[:, :4]\n",
    "y = df[:].values\n",
    "y = y[:, 4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Matt\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(y)\n",
    "y = label_encoder.transform(y) + 1\n",
    "\n",
    "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'red'>TODO</font>: Plot the distributions of the four different features in 1-dimensional histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be mentioned that LDA assumes normal distributed data, features that are statistically independent, and identical covariance matrices for every class. However, this only applies for LDA as classifier and LDA for dimensionality reduction can also work reasonably well if those assumptions are violated. And even for classification tasks LDA seems can be quite robust to the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Computing the d-dimensional mean vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Vector class 1: [5.005999999999999 3.4180000000000006 1.464 0.2439999999999999]\n",
      "\n",
      "Mean Vector class 2: [5.936 2.7700000000000005 4.26 1.3259999999999998]\n",
      "\n",
      "Mean Vector class 3: [6.587999999999998 2.9739999999999998 5.552 2.026]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "\n",
    "mean_vectors = []\n",
    "# Your code...\n",
    "for cl in range(1,4):\n",
    "    mean_vectors.append(np.mean(X[y==cl], axis = 0))\n",
    "    print('Mean Vector class %s: %s\\n' %(cl, mean_vectors[cl-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Computing the Scatter Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the \"within-class scatter matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within-class Scatter Matrix:\n",
      " [[38.956199999999995 13.682999999999996 24.614000000000004\n",
      "  5.6556000000000015]\n",
      " [13.682999999999996 17.035000000000004 8.12 4.9132]\n",
      " [24.614000000000004 8.12 27.220000000000017 6.2536000000000005]\n",
      " [5.6556000000000015 4.9132 6.2536000000000005 6.175599999999998]]\n"
     ]
    }
   ],
   "source": [
    "S_W = np.zeros((4,4))\n",
    "\n",
    "# Your Code...\n",
    "\n",
    "for cl,mv in zip(range(1,4), mean_vectors):\n",
    "    class_scatter_mat = np.zeros((4,4))\n",
    "    for row in X[y==cl]:\n",
    "        row, mv = row.reshape(4,1), mv.reshape(4,1)\n",
    "        class_scatter_mat = class_scatter_mat + (row-mv).dot((row-mv).T)\n",
    "    S_W = S_W + class_scatter_mat\n",
    "\n",
    "# scatter matrix for every class\n",
    "\n",
    "# make column vectors\n",
    "\n",
    "# sum class scatter matrices\n",
    "print('within-class Scatter Matrix:\\n', S_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute \"between-class scatter matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between-class Scatter Matrix:\n",
      " [[63.21213333333327 -19.534000000000034 165.16466666666656\n",
      "  71.36306666666663]\n",
      " [-19.534000000000034 10.97760000000001 -56.05520000000008\n",
      "  -22.492400000000032]\n",
      " [165.16466666666656 -56.05520000000008 436.6437333333333\n",
      "  186.90813333333332]\n",
      " [71.36306666666663 -22.492400000000032 186.90813333333332\n",
      "  80.60413333333332]]\n"
     ]
    }
   ],
   "source": [
    "overall_mean = np.mean(X, axis=0)\n",
    "\n",
    "S_B = np.zeros((4,4))\n",
    "\n",
    "# Your code...\n",
    "for i,mean_vecs in enumerate(mean_vectors):\n",
    "    n = X[y==i+1,:].shape[0]\n",
    "    mean_vecs = mean_vecs.reshape(4,1)\n",
    "    overall_mean = overall_mean.reshape(4,1)\n",
    "    S_B = S_B + n*(mean_vecs - overall_mean).dot((mean_vecs-overall_mean).T)\n",
    "# make column vector\n",
    "\n",
    "print('between-class Scatter Matrix:\\n', S_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_B = S_B.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_W = S_W.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Eigen Vectors and Eigen Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eigenvector1: \n",
      "[[-0.2049]\n",
      " [-0.3871]\n",
      " [ 0.5465]\n",
      " [ 0.7138]]\n",
      "Eigenvalue 1: 3.23e+01\n",
      "\n",
      "\n",
      "Eigenvector2: \n",
      "[[-0.009 ]\n",
      " [-0.589 ]\n",
      " [ 0.2543]\n",
      " [-0.767 ]]\n",
      "Eigenvalue 2: 2.78e-01\n",
      "\n",
      "\n",
      "Eigenvector3: \n",
      "[[ 0.6104]\n",
      " [-0.3325]\n",
      " [-0.3415]\n",
      " [ 0.1585]]\n",
      "Eigenvalue 3: 1.48e-15\n",
      "\n",
      "\n",
      "Eigenvector4: \n",
      "[[ 0.6104]\n",
      " [-0.3325]\n",
      " [-0.3415]\n",
      " [ 0.1585]]\n",
      "Eigenvalue 4: 1.48e-15\n"
     ]
    }
   ],
   "source": [
    "# Your code...\n",
    "eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "\n",
    "for i in range(len(eig_vals)):\n",
    "    eigvec_sc = eig_vecs[:,i].reshape(4,1)\n",
    "    print('\\n')\n",
    "    print('Eigenvector{}: \\n{}'.format(i+1, eigvec_sc.real))\n",
    "    print('Eigenvalue {:}: {:.2e}'.format(i+1, eig_vals[i].real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Solving the generalized eigenvalue problem for the matrix $S^{−1}_{W}. S_{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(eig_vals)):\n",
    "    eigv = eig_vecs[:,i].reshape(4,1)\n",
    "    np.testing.assert_array_almost_equal(np.linalg.inv(S_W).dot(S_B).dot(eigv),\n",
    "                                         eig_vals[i] * eigv,\n",
    "                                         decimal=6, err_msg='', verbose=True)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Selecting linear discriminants for the new feature subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write code for the following..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in decreasing order:\n",
      "\n",
      "32.27195779972982\n",
      "0.27756686384004503\n",
      "6.613543721484293e-15\n",
      "6.613543721484293e-15\n"
     ]
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "#Your code...\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "# Your Code\n",
    "eig_pairs.sort(key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "\n",
    "print('Eigenvalues in decreasing order:\\n')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained:\n",
      "\n",
      "eigenvalue 1: 99.15%\n",
      "eigenvalue 2: 0.85%\n",
      "eigenvalue 3: 0.00%\n",
      "eigenvalue 4: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print('Variance explained:\\n')\n",
    "eigv_sum = sum(eig_vals)\n",
    "for i,j in enumerate(eig_pairs):\n",
    "    print('eigenvalue {0:}: {1:.2%}'.format(i+1, (j[0]/eigv_sum).real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Choosing k eigenvectors with the largest eigenvalues\n",
    "\n",
    "After sorting the eigenpairs by decreasing eigenvalues, it is now time to construct our k×d-dimensional eigenvector matrix WW (here 4×2: based on the 2 most informative eigenpairs) and thereby reducing the initial 4-dimensional feature space into a 2-dimensional feature subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[-0.2049 -0.009 ]\n",
      " [-0.3871 -0.589 ]\n",
      " [ 0.5465  0.2543]\n",
      " [ 0.7138 -0.767 ]]\n"
     ]
    }
   ],
   "source": [
    "W = np.hstack((eig_pairs[0][1].reshape(4,1), eig_pairs[1][1].reshape(4,1)))\n",
    "print('Matrix W:\\n', W.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'red'>TODO</font>: Try to plot projection onto the new feature space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
